{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets tqdm python-dotenv --quiet\n",
    "%pip install -U -q \"google-genai>=1.10.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "MODEL_ID = \"gemini-2.5-flash-preview-04-17\"\n",
    "OUTPUT_FILE = \"./data/train_reasoning.jsonl\" # File to save results\n",
    "MAX_CALLS_PER_RUN = 9900 # Set slightly below 10k limit as a safety margin\n",
    "DELAY_BETWEEN_CALLS_SEC = 1 # Simple delay to avoid hitting RPM limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "You are an AI language expert simulating the process of text editing. You will receive a source text (`src`) which contains an editing instruction followed by the text to be edited.\n",
    "\n",
    "Your task is to:\n",
    "1.  Carefully identify the editing instruction given at the beginning of the `src` text.\n",
    "2.  Analyze the original text segment that follows the instruction in `src`.\n",
    "3.  Apply the instruction step-by-step to the original text.\n",
    "4.  For each step or change you make, articulate the precise reasoning based on linguistic rules, the instruction's goal (e.g., grammar, clarity, simplification), or common writing conventions. Explain *why* a change is necessary or beneficial according to the instruction.\n",
    "5.  Your reasoning should demonstrate *how* to arrive at the corrected text, simulating the thought process of performing the edit yourself.\n",
    "\n",
    "**Crucially:** Your reasoning process should *not* refer to or imply knowledge of a pre-existing target or corrected text. Focus *only* on applying the instruction to the source text to derive the necessary changes.\n",
    "\n",
    "Your entire output must consist *only* of the step-by-step reasoning process, enclosed within `<think></think>` tags. Do not include the original instruction, the source text, the final corrected text, or any other text outside these tags.\n",
    "\n",
    "**Example Interaction:**\n",
    "\n",
    "**User Input (constructed from your dataset):**\n",
    "\n",
    "```\n",
    "Source (src): Fix grammar in this sentence: If engineers do not come up with new ideas, they cannot find best solution for the problems.\n",
    "Target (tgt): If engineers do not come up with new ideas, they cannot find the best solution for different problems.\n",
    "```\n",
    "\n",
    "**Your Expected Output (demonstrating the reasoning to *derive* the correction):**\n",
    "\n",
    "```xml\n",
    "<think>\n",
    "1. Instruction analysis: The task is to \"Fix grammar\". This requires identifying and correcting grammatical errors in the sentence \"If engineers do not come up with new ideas, they cannot find best solution for the problems.\"\n",
    "2. Sentence segment analysis: The first clause \"If engineers do not come up with new ideas\" appears grammatically sound.\n",
    "3. Focus on the second clause: \"they cannot find best solution for the problems.\"\n",
    "4. Identify potential error 1: The noun phrase \"best solution\". \"Best\" is a superlative adjective. Grammatical rule: Superlative adjectives modifying singular countable nouns generally require a definite article (\"the\").\n",
    "5. Apply correction 1: Insert \"the\" before \"best solution\". The phrase becomes \"the best solution\".\n",
    "6. Identify potential error/improvement area 2: The phrase \"for the problems\". While grammatically plausible, using \"the\" implies specific, previously identified problems. The context seems general. Improving grammatical flow or clarity might involve adjusting this.\n",
    "7. Consider alternatives for \"the problems\": \"for problems\" (too general?), \"for specific problems\" (adds info), \"for different problems\" (suggests variety, often fits general statements well).\n",
    "8. Apply correction 2: Replace \"the problems\" with \"different problems\" for better contextual fit and naturalness, aligning with the goal of general grammatical improvement and clarity often included in \"Fix grammar\" tasks.\n",
    "9. Synthesized correction based on reasoning: The corrected clause is \"they cannot find the best solution for different problems.\" The full sentence derived from applying the grammar fixes is \"If engineers do not come up with new ideas, they cannot find the best solution for different problems.\"\n",
    "</think>\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded: 69071 rows\n",
      "Loaded 0 processed IDs from ./data/train_reasoning.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d63a2f2c684487f98cdec2068a325dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing dataset:   0%|          | 0/69071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --- Helper Function to Load Processed IDs ---\n",
    "\n",
    "def load_processed_ids(filename):\n",
    "    processed = set()\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if '_id' in data:\n",
    "                        processed.add(data['_id'])\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Warning: Skipping invalid JSON line in {filename}\")\n",
    "    print(f\"Loaded {len(processed)} processed IDs from {filename}\")\n",
    "    return processed\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "\n",
    "if not gemini_api_key:\n",
    "    print(\"Error: GEMINI_API_KEY not found in environment variables.\")\n",
    "else:\n",
    "    # Initialize client\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        # Using shuffle=False here to process in a consistent order across runs\n",
    "        train_ds = load_dataset(\"grammarly/coedit\", split=\"train\", cache_dir=\"./data\")\n",
    "        print(f\"Dataset loaded: {len(train_ds)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal Error: Could not load dataset. {e}\")\n",
    "        train_ds = None # Ensure loop doesn't run\n",
    "\n",
    "if train_ds:\n",
    "    # Load IDs that have already been processed\n",
    "    processed_ids = load_processed_ids(OUTPUT_FILE)\n",
    "    api_calls_made_this_run = 0\n",
    "\n",
    "    # Open the output file in append mode\n",
    "    with open(OUTPUT_FILE, 'a', encoding='utf-8') as outfile:\n",
    "        # Iterate through the dataset with a progress bar\n",
    "        for item in tqdm(train_ds, desc=\"Processing dataset\"):\n",
    "            item_id = item['_id']\n",
    "            item_src = item['src']\n",
    "            item_tgt = item['tgt']\n",
    "\n",
    "            # Check if we need to stop due to API limit\n",
    "            if api_calls_made_this_run >= MAX_CALLS_PER_RUN:\n",
    "                print(f\"\\nReached API call limit for this run ({MAX_CALLS_PER_RUN}). Stopping.\")\n",
    "                break\n",
    "\n",
    "            # Skip if already processed in a previous run\n",
    "            if item_id in processed_ids:\n",
    "                continue # Skip to the next item\n",
    "\n",
    "            # --- Prepare API Call ---\n",
    "            user_prompt = f\"Source (src): {item_src}\\nTarget (tgt): {item_tgt}\"\n",
    "\n",
    "            try:\n",
    "                # --- Make API Call ---\n",
    "                response = client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    contents=user_prompt,\n",
    "                    config=types.GenerateContentConfig(\n",
    "                        system_instruction=sys_prompt,\n",
    "                        thinking_config=types.ThinkingConfig(\n",
    "                            thinking_budget=500 # 0 means no thinking None means no limit to thinking it can take however many tokens it wants.\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # --- Process Response ---\n",
    "                reasoning_text = response.text # Assuming the response.text directly contains the <think> block\n",
    "\n",
    "                # Basic check if the output looks like the expected format\n",
    "                if reasoning_text and reasoning_text.strip().startswith(\"<think>\") and reasoning_text.strip().endswith(\"</think>\"):\n",
    "                    result_data = {\n",
    "                        \"_id\": item_id,\n",
    "                        \"reasoning\": reasoning_text.strip() # Store the reasoning\n",
    "                    }\n",
    "\n",
    "                    # Write the result as a JSON line\n",
    "                    json_line = json.dumps(result_data)\n",
    "                    outfile.write(json_line + '\\n')\n",
    "                    outfile.flush() # Ensure it's written immediately\n",
    "\n",
    "                    # Update tracking\n",
    "                    processed_ids.add(item_id)\n",
    "                    api_calls_made_this_run += 1\n",
    "\n",
    "                else:\n",
    "                    print(f\"\\nWarning: Unexpected response format for ID {item_id}. Skipping. Response: {reasoning_text[:200]}...\") # Print start of unexpected response\n",
    "\n",
    "            except Exception as e:\n",
    "                # Basic error handling for the API call\n",
    "                print(f\"\\nError processing ID {item_id}: {e}\")\n",
    "                # Optionally add the ID to a separate error log file here\n",
    "\n",
    "            # --- Delay ---\n",
    "            time.sleep(DELAY_BETWEEN_CALLS_SEC)\n",
    "\n",
    "\n",
    "        print(f\"\\nFinished processing. Made {api_calls_made_this_run} API calls in this run.\")\n",
    "        print(f\"Total processed IDs (including previous runs): {len(processed_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the token counts (use 0 if Thoughts tokens is None or zero):\n",
      "\n",
      "Calculating using THINKING output price ($3.50 / 1M tokens)\n",
      "\n",
      "--- Cost Breakdown ---\n",
      "Input Cost:       $0.000120\n",
      "Output Cost:      $0.003507 (based on 1002 billable output tokens)\n",
      "----------------------\n",
      "Total Estimated Cost: $0.003627\n",
      "\n",
      "Estimated Cost for 70,000 calls: $253.89\n"
     ]
    }
   ],
   "source": [
    "# Pricing per 1 Million tokens\n",
    "INPUT_PRICE_PER_MILLION = 0.15\n",
    "OUTPUT_NON_THINKING_PRICE_PER_MILLION = 0.60\n",
    "OUTPUT_THINKING_PRICE_PER_MILLION = 3.50\n",
    "\n",
    "# --- Get Token Counts from User ---\n",
    "print(\"Enter the token counts (use 0 if Thoughts tokens is None or zero):\")\n",
    "\n",
    "prompt_tokens = 800\n",
    "thoughts_tokens = 393 # Assume 0 if None was the actual value\n",
    "output_tokens = 609\n",
    "\n",
    "# --- Calculate Costs ---\n",
    "\n",
    "# Input Cost\n",
    "input_cost = (prompt_tokens / 1_000_000) * INPUT_PRICE_PER_MILLION\n",
    "\n",
    "# Output Cost (depends on whether thinking tokens were generated)\n",
    "if thoughts_tokens > 0:\n",
    "    # Thinking was used - price applies to output + thoughts tokens\n",
    "    billable_output_tokens = output_tokens + thoughts_tokens\n",
    "    output_cost = (billable_output_tokens / 1_000_000) * OUTPUT_THINKING_PRICE_PER_MILLION\n",
    "    print(\"\\nCalculating using THINKING output price ($3.50 / 1M tokens)\")\n",
    "else:\n",
    "    # No thinking - price applies only to output tokens\n",
    "    billable_output_tokens = output_tokens\n",
    "    output_cost = (billable_output_tokens / 1_000_000) * OUTPUT_NON_THINKING_PRICE_PER_MILLION\n",
    "    print(\"\\nCalculating using NON-THINKING output price ($0.60 / 1M tokens)\")\n",
    "\n",
    "# Total Cost\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "# --- Display Results ---\n",
    "print(f\"\\n--- Cost Breakdown ---\")\n",
    "print(f\"Input Cost:       ${input_cost:.6f}\")\n",
    "print(f\"Output Cost:      ${output_cost:.6f} (based on {billable_output_tokens} billable output tokens)\")\n",
    "print(f\"----------------------\")\n",
    "print(f\"Total Estimated Cost: ${total_cost:.6f}\")\n",
    "\n",
    "# Example calculation for 10,000 identical calls\n",
    "num_calls = 70000\n",
    "total_cost_10k = total_cost * num_calls\n",
    "print(f\"\\nEstimated Cost for {num_calls:,} calls: ${total_cost_10k:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
