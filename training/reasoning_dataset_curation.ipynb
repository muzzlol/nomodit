{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (1.24.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.4.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading aiohttp-3.11.18-cp311-cp311-macosx_11_0_arm64.whl (457 kB)\n",
      "Downloading multidict-6.4.3-cp311-cp311-macosx_11_0_arm64.whl (37 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp311-cp311-macosx_11_0_arm64.whl (122 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-macosx_12_0_arm64.whl (30.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.9/30.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "\u001b[?25l\u001b[33m  WARNING: The script tqdm is installed in '/Library/Frameworks/Python.framework/Versions/3.11/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: requests\n",
      "\u001b[2K    Found existing installation: requests 2.22.0\n",
      "\u001b[2K    Uninstalling requests-2.22.0:\n",
      "\u001b[2K      Successfully uninstalled requests-2.22.0\n",
      "\u001b[2K  Attempting uninstall: pyarrow\n",
      "\u001b[2K    Found existing installation: pyarrow 12.0.1\n",
      "\u001b[2K    Uninstalling pyarrow-12.0.1:\n",
      "\u001b[2K      Successfully uninstalled pyarrow-12.0.1\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m12/16\u001b[0m [huggingface-hub]\u001b[33m  WARNING: The script huggingface-cli is installed in '/Library/Frameworks/Python.framework/Versions/3.11/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m15/16\u001b[0m [datasets]\u001b[33m  WARNING: The script datasets-cli is installed in '/Library/Frameworks/Python.framework/Versions/3.11/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 datasets-3.5.1 dill-0.3.8 frozenlist-1.6.0 fsspec-2025.3.0 huggingface-hub-0.30.2 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "try:\n",
    "    train_ds = load_dataset(\"grammarly/coedit\", split=\"train\", cache_dir=\"./data\")\n",
    "    val_ds = load_dataset(\"grammarly/coedit\", split=\"validation\", cache_dir=\"./data\")\n",
    "except ValueError as e:\n",
    "    print(f\"ran into error while loading dataset: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['_id', 'task', 'src', 'tgt'],\n",
      "    num_rows: 69071\n",
      "})\n",
      "Dataset({\n",
      "    features: ['_id', 'task', 'src', 'tgt'],\n",
      "    num_rows: 1712\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: google-genai 1.13.0\n",
      "Uninstalling google-genai-1.13.0:\n",
      "  Successfully uninstalled google-genai-1.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall google-genai -y\n",
    "%pip install -U -q \"google-genai>=1.10.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "1.  **Instruction Analysis:** The task is to \"Remove all grammatical errors\" from the provided sentence. This requires identifying and correcting any grammatical mistakes in the sentence \"Safety is one of the crucial problems that many countries and companies concern.\"\n",
      "2.  **Sentence Analysis:** The sentence structure is \"Subject (Safety) + Verb (is) + Complement (one of the crucial problems) + Relative Clause (that many countries and companies concern)\".\n",
      "3.  **Focus on the Relative Clause:** The phrase \"that many countries and companies concern\" is where the potential error lies. The verb \"concern\" is being used actively here, apparently with \"many countries and companies\" as the subject and \"problems\" (implied as the antecedent of \"that\") as the direct object.\n",
      "4.  **Analyze the Usage of \"concern\":** The active verb \"concern\" typically means 'to relate to' or 'to affect'. For example, \"The rule concerns all employees\" or \"This matter concerns your safety.\" In the source sentence, the intended meaning seems to be that countries and companies *have worry or interest about* these problems, not that they *affect* or *are related to* the problems in an active sense.\n",
      "5.  **Identify the Grammatical Error:** Using the active verb \"concern\" in this relative clause structure (\"problems that many countries and companies concern\") is ungrammatical for expressing the idea that the problems are the subject of worry or attention for the countries and companies. The structure needs to indicate that the countries and companies are the ones experiencing the concern *about* the problems.\n",
      "6.  **Determine the Correct Structure:** To express that someone *has concern about* something, we typically use the passive construction \"be concerned about\" or the noun phrase \"have concern about\". Since the relative clause is modifying \"problems\", it needs to describe the problems *as* the things about which countries and companies are concerned.\n",
      "7.  **Apply Correction:** Rewrite the relative clause to reflect this passive relationship. Instead of \"that many countries and companies concern [them]\", it should be \"that many countries and companies *are concerned about*\". The antecedent \"problems\" is what they are concerned *about*. The pronoun referring back to \"problems\" is needed after \"about\".\n",
      "8.  **Refine Correction:** The structure \"problems that they are concerned about\" is common. Replacing \"they\" with the original subject \"many countries and companies\" gives \"problems that many countries and companies are concerned about\". This correctly expresses that the problems are the object of concern for the countries and companies.\n",
      "9.  **Final Check:** The corrected sentence \"Safety is one of the crucial problems that many countries and companies are concerned about\" is grammatically sound and accurately conveys the likely intended meaning. The phrase \"are concerned about\" correctly uses the passive voice and the necessary preposition to show what the concern is directed towards.\n",
      "</think>\n",
      "\n",
      "Prompt tokens: 791\n",
      "Thoughts tokens: 393\n",
      "Output tokens: 609\n",
      "Total tokens: 1793\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=gemini_api_key)\n",
    "MODEL_ID=\"gemini-2.5-flash-preview-04-17\"\n",
    "\n",
    "\n",
    "src = \"Remove all grammatical errors from this text: Safety is one of the crucial problems that many countries and companies concern.\"\n",
    "tgt = \"Safety is one of the crucial problems that many countries and companies are concerned about.\"\n",
    "prompt = f\"Source (src): {src}\\nTarget (tgt): {tgt}\"\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "```system\n",
    "You are an expert linguistic analyzer simulating the process of text editing. You will receive a source text (`src`) which contains an editing instruction followed by the text to be edited.\n",
    "\n",
    "Your task is to:\n",
    "1.  Carefully identify the editing instruction given at the beginning of the `src` text.\n",
    "2.  Analyze the original text segment that follows the instruction in `src`.\n",
    "3.  Apply the instruction step-by-step to the original text.\n",
    "4.  For each step or change you make, articulate the precise reasoning based on linguistic rules, the instruction's goal (e.g., grammar, clarity, simplification), or common writing conventions. Explain *why* a change is necessary or beneficial according to the instruction.\n",
    "5.  Your reasoning should demonstrate *how* to arrive at the corrected text, simulating the thought process of performing the edit yourself.\n",
    "\n",
    "**Crucially:** Your reasoning process should *not* refer to or imply knowledge of a pre-existing target or corrected text. Focus *only* on applying the instruction to the source text to derive the necessary changes.\n",
    "\n",
    "Your entire output must consist *only* of the step-by-step reasoning process, enclosed within `<think></think>` tags. Do not include the original instruction, the source text, the final corrected text, or any other text outside these tags.\n",
    "\n",
    "**Example Interaction:**\n",
    "\n",
    "**User Input (constructed from your dataset):**\n",
    "\n",
    "```\n",
    "Source (src): Fix grammar in this sentence: If engineers do not come up with new ideas, they cannot find best solution for the problems.\n",
    "Target (tgt): If engineers do not come up with new ideas, they cannot find the best solution for different problems.\n",
    "```\n",
    "\n",
    "**Your Expected Output (demonstrating the reasoning to *derive* the correction):**\n",
    "\n",
    "```xml\n",
    "<think>\n",
    "1. Instruction analysis: The task is to \"Fix grammar\". This requires identifying and correcting grammatical errors in the sentence \"If engineers do not come up with new ideas, they cannot find best solution for the problems.\"\n",
    "2. Sentence segment analysis: The first clause \"If engineers do not come up with new ideas\" appears grammatically sound.\n",
    "3. Focus on the second clause: \"they cannot find best solution for the problems.\"\n",
    "4. Identify potential error 1: The noun phrase \"best solution\". \"Best\" is a superlative adjective. Grammatical rule: Superlative adjectives modifying singular countable nouns generally require a definite article (\"the\").\n",
    "5. Apply correction 1: Insert \"the\" before \"best solution\". The phrase becomes \"the best solution\".\n",
    "6. Identify potential error/improvement area 2: The phrase \"for the problems\". While grammatically plausible, using \"the\" implies specific, previously identified problems. The context seems general. Improving grammatical flow or clarity might involve adjusting this.\n",
    "7. Consider alternatives for \"the problems\": \"for problems\" (too general?), \"for specific problems\" (adds info), \"for different problems\" (suggests variety, often fits general statements well).\n",
    "8. Apply correction 2: Replace \"the problems\" with \"different problems\" for better contextual fit and naturalness, aligning with the goal of general grammatical improvement and clarity often included in \"Fix grammar\" tasks.\n",
    "9. Synthesized correction based on reasoning: The corrected clause is \"they cannot find the best solution for different problems.\" The full sentence derived from applying the grammar fixes is \"If engineers do not come up with new ideas, they cannot find the best solution for different problems.\"\n",
    "</think>\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=sys_prompt,\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            thinking_budget=500 # 0 means no thinking None means no limit to thinking it can take however many tokens it wants.\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(response.text)\n",
    "print()\n",
    "print(\"Prompt tokens:\",response.usage_metadata.prompt_token_count)\n",
    "print(\"Thoughts tokens:\",response.usage_metadata.thoughts_token_count)\n",
    "print(\"Output tokens:\",response.usage_metadata.candidates_token_count)\n",
    "print(\"Total tokens:\",response.usage_metadata.total_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the token counts (use 0 if Thoughts tokens is None or zero):\n",
      "\n",
      "Calculating using THINKING output price ($3.50 / 1M tokens)\n",
      "\n",
      "--- Cost Breakdown ---\n",
      "Input Cost:       $0.000120\n",
      "Output Cost:      $0.003507 (based on 1002 billable output tokens)\n",
      "----------------------\n",
      "Total Estimated Cost: $0.003627\n",
      "\n",
      "Estimated Cost for 10,000 calls: $36.27\n"
     ]
    }
   ],
   "source": [
    "# Pricing per 1 Million tokens\n",
    "INPUT_PRICE_PER_MILLION = 0.15\n",
    "OUTPUT_NON_THINKING_PRICE_PER_MILLION = 0.60\n",
    "OUTPUT_THINKING_PRICE_PER_MILLION = 3.50\n",
    "\n",
    "# --- Get Token Counts from User ---\n",
    "print(\"Enter the token counts (use 0 if Thoughts tokens is None or zero):\")\n",
    "\n",
    "prompt_tokens = 800\n",
    "thoughts_tokens = 393 # Assume 0 if None was the actual value\n",
    "output_tokens = 609\n",
    "\n",
    "# --- Calculate Costs ---\n",
    "\n",
    "# Input Cost\n",
    "input_cost = (prompt_tokens / 1_000_000) * INPUT_PRICE_PER_MILLION\n",
    "\n",
    "# Output Cost (depends on whether thinking tokens were generated)\n",
    "if thoughts_tokens > 0:\n",
    "    # Thinking was used - price applies to output + thoughts tokens\n",
    "    billable_output_tokens = output_tokens + thoughts_tokens\n",
    "    output_cost = (billable_output_tokens / 1_000_000) * OUTPUT_THINKING_PRICE_PER_MILLION\n",
    "    print(\"\\nCalculating using THINKING output price ($3.50 / 1M tokens)\")\n",
    "else:\n",
    "    # No thinking - price applies only to output tokens\n",
    "    billable_output_tokens = output_tokens\n",
    "    output_cost = (billable_output_tokens / 1_000_000) * OUTPUT_NON_THINKING_PRICE_PER_MILLION\n",
    "    print(\"\\nCalculating using NON-THINKING output price ($0.60 / 1M tokens)\")\n",
    "\n",
    "# Total Cost\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "# --- Display Results ---\n",
    "print(f\"\\n--- Cost Breakdown ---\")\n",
    "print(f\"Input Cost:       ${input_cost:.6f}\")\n",
    "print(f\"Output Cost:      ${output_cost:.6f} (based on {billable_output_tokens} billable output tokens)\")\n",
    "print(f\"----------------------\")\n",
    "print(f\"Total Estimated Cost: ${total_cost:.6f}\")\n",
    "\n",
    "# Example calculation for 10,000 identical calls\n",
    "num_calls = 10000\n",
    "total_cost_10k = total_cost * num_calls\n",
    "print(f\"\\nEstimated Cost for {num_calls:,} calls: ${total_cost_10k:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
